{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDM-1609/Statistical-Process-Control-in-Injection-Machines/blob/main/SPC_Analysis_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFJ7fzx_0h7-"
      },
      "source": [
        "# EXTRACCIÓN DE ESTADÍSTICOS INICIALES"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEPARACIÓN MANUAL DE LAS SECCIONES DEL CSV**\n",
        "\n",
        "El siguiente código separa en DataFrames diferentes cada una de las secciones del CSV (Info. Contextual, estadísticos y datos crudos) de manera manual, dado que se le debe especificar los indices en donde comienza y termina cada sección. Este código tiene como limitante que si la distribución de los datos del CSV cambia el codigo se rompe (se tendrían que especificar los nuevos indices de inicio y fin de cada sección)"
      ],
      "metadata": {
        "id": "XxnVr-S0U9os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "\n",
        "# OPCIONAL: para visualización de los datos en el DF\n",
        "\n",
        "# pd.set_option(\"display.max_columns\", 20) # Controla cuántas columnas se muestran\n",
        "# pd.set_option(\"display.float_format\", lambda v: f\"{v:.4g}\") # Muestra valores con hasta 4 cifras significativas\n",
        "\n",
        "# Encoding de los archivos del ALS\n",
        "ENCODING_ALS = \"cp1250\"\n"
      ],
      "metadata": {
        "id": "AT8w6DbGVIHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "RUTA_IN = next(iter(uploaded.keys()))\n",
        "print(\"Archivo cargado:\", RUTA_IN)\n"
      ],
      "metadata": {
        "id": "lliG8KM6WJni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices para start & end de cada sección\n",
        "# SECCIONES\n",
        "idx_info = 0           # Información contextual\n",
        "idx_stats_start = 2    # Start Estadísticos\n",
        "idx_stats_end = 21     # End Estadísticos\n",
        "idx_raw_start = 23     # Datos crudos"
      ],
      "metadata": {
        "id": "mXETDW2dZFeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCIONES EMPLEADAS\n",
        "\n",
        "# Lee el CSV como strings y devuelve una lista donde cada elemento es una linea del CSV\n",
        "def leer_lineas(ruta_csv: str, encoding: str = ENCODING_ALS):\n",
        "    raw = Path(ruta_csv).read_text(encoding=encoding, errors=\"replace\")\n",
        "    lines = raw.splitlines()\n",
        "    return lines\n",
        "\n",
        "# Devuelve la sección \"Información Contextual\" como un DF\n",
        "def parse_info_contextual(lines, idx_info: int = 0) -> pd.DataFrame:\n",
        "    line = lines[idx_info]\n",
        "    cells = next(csv.reader([line], delimiter=\",\", quotechar='\"'))\n",
        "\n",
        "    # Hay celdas vacías entre pares clave-valor, por eso usamos un bucle manual.\n",
        "    claves = []\n",
        "    valores = []\n",
        "    i = 0\n",
        "    while i < len(cells):\n",
        "        key = cells[i].strip().strip('\"')\n",
        "        val = \"\"\n",
        "        if i + 1 < len(cells):\n",
        "            val = cells[i + 1].strip().strip('\"')\n",
        "        # Filtramos entradas vacías o etiquetas tipo \"Valores reales\"\n",
        "        if key and key.lower() not in {\"valores reales\"}:\n",
        "            claves.append(key)\n",
        "            valores.append(val)\n",
        "        i += 2  # saltamos al siguiente par\n",
        "\n",
        "    # Construimos un DataFrame de una sola fila\n",
        "    df_info = pd.DataFrame([valores], columns=claves)\n",
        "    return df_info\n",
        "\n",
        "\n",
        "def parse_estadisticos(lines, idx_start: int, idx_end: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Toma el bloque de 'Estadísticos' entre las líneas [idx_start:idx_end]\n",
        "    y lo convierte en un DataFrame.\n",
        "    \"\"\"\n",
        "    # Unimos las líneas de la sección en un solo string tipo CSV\n",
        "    block = \"\\n\".join(lines[idx_start:idx_end])\n",
        "\n",
        "    # Leemos este bloque como si fuera un CSV independiente\n",
        "    df_stats = pd.read_csv(\n",
        "        StringIO(block),\n",
        "        sep=\",\",\n",
        "        decimal=\",\",\n",
        "        thousands=\".\",\n",
        "        quotechar='\"',\n",
        "        encoding=ENCODING_ALS,\n",
        "        engine=\"python\",\n",
        "    )\n",
        "\n",
        "    # Opcional: renombrar la primera columna a 'Estadístico'\n",
        "    first_col = df_stats.columns[0]\n",
        "    df_stats.rename(columns={first_col: \"Estadístico\"}, inplace=True)\n",
        "\n",
        "    return df_stats\n",
        "\n",
        "\n",
        "def parse_datos_crudos(lines, idx_start: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Toma el bloque de 'Datos crudos' desde idx_start hasta el final del archivo\n",
        "    y lo convierte en DataFrame.\n",
        "    \"\"\"\n",
        "    block = \"\\n\".join(lines[idx_start:])  # desde idx_start hasta EOF\n",
        "\n",
        "    df_raw = pd.read_csv(\n",
        "        StringIO(block),\n",
        "        sep=\",\",\n",
        "        decimal=\",\",\n",
        "        thousands=\".\",\n",
        "        quotechar='\"',\n",
        "        encoding=ENCODING_ALS,\n",
        "        engine=\"python\",\n",
        "    )\n",
        "\n",
        "    return df_raw\n"
      ],
      "metadata": {
        "id": "BRFxLC15ZFcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Ejecutar: cortar secciones y obtener DataFrames\n",
        "# ============================\n",
        "\n",
        "# 1) Leer todas las líneas del archivo\n",
        "lines = leer_lineas(RUTA_IN, encoding=ENCODING_ALS)\n",
        "print(f\"Número total de líneas en el archivo: {len(lines)}\")\n",
        "\n",
        "# 2) Información contextual\n",
        "df_info = parse_info_contextual(lines, idx_info=idx_info)\n",
        "print(\"Información contextual (DataFrame):\")\n",
        "display(df_info)\n",
        "\n",
        "# 3) Estadísticos\n",
        "df_stats = parse_estadisticos(lines, idx_start=idx_stats_start, idx_end=idx_stats_end)\n",
        "print(\"Estadísticos (vista rápida):\")\n",
        "display(df_stats.head())\n",
        "\n",
        "# 4) Datos crudos\n",
        "df_raw = parse_datos_crudos(lines, idx_start=idx_raw_start)\n",
        "print(\"Datos crudos (vista rápida):\")\n",
        "display(df_raw.head())\n"
      ],
      "metadata": {
        "id": "ohXJPHp5ZFZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Guardar cada sección en CSV (opcional)\n",
        "# ============================\n",
        "\n",
        "df_info.to_csv(\"ALS_info_contextual.csv\", index=False, encoding=\"utf-8\")\n",
        "df_stats.to_csv(\"ALS_estadisticos.csv\", index=False, encoding=\"utf-8\")\n",
        "df_raw.to_csv(\"ALS_datos_crudos.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Archivos generados:\")\n",
        "print(\" - ALS_info_contextual.csv\")\n",
        "print(\" - ALS_estadisticos.csv\")\n",
        "print(\" - ALS_datos_crudos.csv\")\n"
      ],
      "metadata": {
        "id": "g72stxB5ZFW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RK9cb6CnZFIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DETECCIÓN Y SEPARACIÓN AUTOMÁTICA DE LAS SECCIONES DEL CSV**\n",
        "\n",
        "El siguiente código separa en DataFrames cada una de las secciones del CSV de manera automática. Este código es más complejo, pero permite su utilización aún si el archivo CSV de origen cambia su distribución."
      ],
      "metadata": {
        "id": "8ItBhGaCUmzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CÓDIGO A UTILIZAR**"
      ],
      "metadata": {
        "id": "K4VxblauU3_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaciones y configuración de display\n",
        "import csv, re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 100)  # Muestra hasta 100 columnas sin ocultar intermedias\n",
        "pd.set_option(\"display.float_format\", lambda v: f\"{v:.6g}\")  # Formato para mostrar flotantes (6 cifras significativas)\n"
      ],
      "metadata": {
        "id": "s01fPdiHm9Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CÓDIGO COMENTADO**\n",
        "\n",
        "Aún necesita ajustes para funcionar"
      ],
      "metadata": {
        "id": "be1pZ10ar6eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Importaciones y configuración\n",
        "# ============================\n",
        "\n",
        "# Módulos estándar\n",
        "import csv       # lector robusto de CSV respetando comillas y separadores\n",
        "import re        # expresiones regulares para limpiar encabezados con unidades\n",
        "from pathlib import Path  # manejo seguro de rutas de archivos\n",
        "\n",
        "# Terceros\n",
        "import pandas as pd  # análisis tabular\n",
        "\n",
        "# Opciones de visualización para que la salida sea clara en Colab\n",
        "pd.set_option(\"display.max_columns\", 100)                    # mostrar muchas columnas sin truncar\n",
        "pd.set_option(\"display.float_format\", lambda v: f\"{v:.6g}\")  # formato compacto de flotantes\n"
      ],
      "metadata": {
        "id": "_3t5IQZgr5jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Funciones auxiliares (helpers)\n",
        "# ============================\n",
        "\n",
        "def _first_cell_lower(line: str):\n",
        "    \"\"\"\n",
        "    Toma una línea cruda del archivo (string), la parsea como CSV y\n",
        "    devuelve la PRIMERA celda en minúsculas, o None si la línea está vacía.\n",
        "    Esto se usa para detectar el encabezado 'Muestra aleatoria' de la sección de datos crudos.\n",
        "    \"\"\"\n",
        "    # csv.reader respeta el separador ',' y las comillas '\"'\n",
        "    cells = next(csv.reader([line], delimiter=\",\", quotechar='\"'))\n",
        "    if not cells:               # línea vacía -> no hay celdas\n",
        "        return None\n",
        "    # quitamos espacios y comillas residuales, y pasamos a minúsculas\n",
        "    return cells[0].strip().strip('\"').lower()\n",
        "\n",
        "\n",
        "def _clean_param_header(name: str) -> str:\n",
        "    \"\"\"\n",
        "    Limpia el nombre de una columna de parámetro:\n",
        "    - elimina unidades entre corchetes (ej. 't4012 [s]' -> 't4012')\n",
        "    - remueve espacios sobrantes\n",
        "    \"\"\"\n",
        "    # patrón: cualquier cosa entre corchetes [ ... ] con espacios opcionales alrededor\n",
        "    name = re.sub(r\"\\s*\\[.*?\\]\\s*\", \"\", str(name))\n",
        "    return name.strip()\n",
        "\n",
        "\n",
        "def _find_section_indices(lines):\n",
        "    \"\"\"\n",
        "    Localiza los índices (número de línea) de las cabeceras de:\n",
        "      - 'Estadísticos' (idx_stats_header): línea donde están los nombres de parámetros (t4012, t4018, ...)\n",
        "      - 'Datos crudos' (idx_raw_header): línea cuya primera celda dice 'Muestra aleatoria'\n",
        "    Devuelve una tupla (idx_stats_header, idx_raw_header). Si alguno no se encuentra, deja None.\n",
        "    \"\"\"\n",
        "    idx_stats_header = None\n",
        "\n",
        "    # Escaneamos las primeras ~120 líneas buscando una cabecera que contenga varias claves típicas\n",
        "    for i, ln in enumerate(lines[:120]):\n",
        "        cells = next(csv.reader([ln], delimiter=\",\", quotechar='\"'))\n",
        "        if not cells:\n",
        "            continue  # línea en blanco\n",
        "        joined = \",\".join(cells).lower()\n",
        "        # Heurística: deben aparecer varios parámetros conocidos en la línea de cabecera\n",
        "        if all(k in joined for k in [\"t4012\", \"t4018\", \"v4065\"]):\n",
        "            idx_stats_header = i\n",
        "            break\n",
        "\n",
        "    idx_raw_header = None\n",
        "    # Recorremos todas las líneas para encontrar la cabecera de 'Datos crudos'\n",
        "    for i, ln in enumerate(lines):\n",
        "        fc = _first_cell_lower(ln)\n",
        "        if fc and fc.startswith(\"muestra aleatoria\"):\n",
        "            idx_raw_header = i\n",
        "            break\n",
        "\n",
        "    return idx_stats_header, idx_raw_header\n"
      ],
      "metadata": {
        "id": "-bcch-ykrukB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Núcleo: lectura + construcción del resumen\n",
        "# ============================\n",
        "\n",
        "def leer_estadisticos(ruta_csv: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lee el CSV del ALS y retorna el bloque 'Estadísticos' como DataFrame.\n",
        "    Maneja el formato específico del ALS:\n",
        "      - separador de campo: ','\n",
        "      - valores numéricos entre comillas '\"...\"'\n",
        "      - coma como separador decimal: decimal=','\n",
        "      - punto como separador de miles: thousands='.'\n",
        "      - codificación latin1 (acentos, caracteres especiales)\n",
        "    \"\"\"\n",
        "    # Leemos el archivo completo como texto para poder detectar secciones por líneas\n",
        "    p = Path(ruta_csv)\n",
        "    raw = p.read_text(encoding=\"latin1\", errors=\"replace\")\n",
        "    lines = raw.splitlines()  # lista de líneas del archivo\n",
        "\n",
        "    # Detectamos índices de inicio de 'Estadísticos' y 'Datos crudos'\n",
        "    idx_stats_header, idx_raw_header = _find_section_indices(lines)\n",
        "    if idx_stats_header is None or idx_raw_header is None:\n",
        "        raise RuntimeError(\n",
        "            f\"No se encontraron cabeceras (stats={idx_stats_header}, raw={idx_raw_header}).\"\n",
        "        )\n",
        "\n",
        "    # Número de filas de la tabla de 'Estadísticos' (excluyendo la cabecera de crudos)\n",
        "    nrows_stats = idx_raw_header - idx_stats_header - 1\n",
        "    if nrows_stats <= 0:\n",
        "        raise RuntimeError(\"Rango de 'Estadísticos' inválido (nrows_stats <= 0).\")\n",
        "\n",
        "    # Leemos solo el bloque de 'Estadísticos' con pandas.read_csv\n",
        "    df_stats = pd.read_csv(\n",
        "        ruta_csv,\n",
        "        skiprows=idx_stats_header,  # salta líneas anteriores y deja la cabecera de parámetros como header=0\n",
        "        nrows=nrows_stats,          # limita la lectura hasta antes de los datos crudos\n",
        "        header=0,\n",
        "        sep=\",\",                    # separador de campo\n",
        "        decimal=\",\",                # coma decimal\n",
        "        thousands=\".\",              # punto de miles\n",
        "        quotechar='\"',              # valores numéricos entre comillas\n",
        "        encoding=\"latin1\",\n",
        "        engine=\"python\",            # motor más tolerante con formatos “no estándar”\n",
        "    )\n",
        "\n",
        "    # Normalizamos el nombre de la primera columna, que contiene el nombre del estadístico\n",
        "    first_col = df_stats.columns[0]\n",
        "    df_stats.rename(columns={first_col: \"Estadístico\"}, inplace=True)\n",
        "\n",
        "    # Limpiamos las unidades de los encabezados de parámetros (t4012 [s] -> t4012)\n",
        "    df_stats.columns = [\"Estadístico\"] + [_clean_param_header(c) for c in df_stats.columns[1:]]\n",
        "\n",
        "    return df_stats\n",
        "\n",
        "\n",
        "def construir_tabla_resumen(df_stats: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve un DataFrame solo con estas filas, en este orden:\n",
        "      - Valor nominal\n",
        "      - Tolerancia inferior\n",
        "      - Tolerancia superior\n",
        "      - xqq\n",
        "      - Sigma\n",
        "      - Cp\n",
        "      - Cpd\n",
        "    Convierte las columnas de parámetros a numérico cuando es posible.\n",
        "    \"\"\"\n",
        "    # Lista objetivo en el orden que se desea reportar\n",
        "    requeridos = [\n",
        "        \"Valor nominal\",\n",
        "        \"Tolerancia inferior\",\n",
        "        \"Tolerancia superior\",\n",
        "        \"xqq\",\n",
        "        \"Sigma\",\n",
        "        \"Cp\",\n",
        "        \"Cpd\",\n",
        "    ]\n",
        "\n",
        "    # Creamos una columna auxiliar en minúsculas para comparar sin problemas de mayúsculas/espacios\n",
        "    df_aux = df_stats.copy()\n",
        "    df_aux[\"__norm__\"] = df_aux[\"Estadístico\"].astype(str).str.strip().str.lower()\n",
        "\n",
        "    # Acumulamos las filas encontradas respetando el orden requerido\n",
        "    out = []\n",
        "    for etiqueta in requeridos:\n",
        "        fila = df_aux[df_aux[\"__norm__\"] == etiqueta.lower()]\n",
        "        if not fila.empty:\n",
        "            out.append(fila.drop(columns=\"__norm__\"))\n",
        "\n",
        "    if not out:\n",
        "        # Si no se encontró nada, algo no coincide con el formato/etiquetas esperadas\n",
        "        raise RuntimeError(\"No se hallaron las filas requeridas en 'Estadísticos'.\")\n",
        "\n",
        "    # Unimos todas las filas y dejamos 'Estadístico' como índice\n",
        "    resumen = pd.concat(out, ignore_index=True).set_index(\"Estadístico\")\n",
        "\n",
        "    # Convertimos todas las columnas (parámetros) a numérico cuando aplique\n",
        "    for c in resumen.columns:\n",
        "        resumen[c] = pd.to_numeric(resumen[c], errors=\"coerce\")\n",
        "\n",
        "    return resumen\n"
      ],
      "metadata": {
        "id": "RWm9Miq4rv65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Subida del archivo CSV (Colab)\n",
        "# ============================\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Abre el cuadro de diálogo para seleccionar archivos\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Tomamos el primer archivo subido y guardamos su nombre en RUTA_IN\n",
        "RUTA_IN = next(iter(uploaded.keys()))\n",
        "print(\"Archivo cargado:\", RUTA_IN)\n"
      ],
      "metadata": {
        "id": "0OSi3_NBrxrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Ejecución: lectura y resumen de 'Estadísticos'\n",
        "# ============================\n",
        "\n",
        "# 1) Leer bloque de 'Estadísticos'\n",
        "df_stats = leer_estadisticos(RUTA_IN)\n",
        "\n",
        "# 2) Construir la tabla solicitada\n",
        "resumen = construir_tabla_resumen(df_stats)\n",
        "\n",
        "# 3) Mostrar resultados en pantalla\n",
        "print(\"Bloque 'Estadísticos' (vista rápida):\")\n",
        "display(df_stats.head(10))\n",
        "\n",
        "print(\"Resumen solicitado (Valor nominal, Tol. inf., Tol. sup., xqq, Sigma, Cp, Cpd):\")\n",
        "display(resumen)\n",
        "\n",
        "# 4) (Opcional) Guardar a CSV el resumen\n",
        "OUT = \"ALS_Estadisticos_Resumen.csv\"\n",
        "resumen.to_csv(OUT, encoding=\"utf-8\")\n",
        "print(\"Guardado:\", OUT)\n"
      ],
      "metadata": {
        "id": "ftirD9HOryy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Validaciones rápidas (opcional)\n",
        "# ============================\n",
        "\n",
        "# Validar que las columnas de parámetros esperadas estén presentes en 'Estadísticos'\n",
        "cols_ok = {\"t4012\", \"t4018\", \"t4015\", \"v4062\", \"p4072\", \"v4065\"}\n",
        "presentes = {c.lower() for c in df_stats.columns}\n",
        "assert cols_ok.issubset(presentes), f\"Faltan columnas en 'Estadísticos': {cols_ok - presentes}\"\n",
        "\n",
        "# Validar que las filas requeridas estén en el resumen\n",
        "esperados = {\"Valor nominal\",\"Tolerancia inferior\",\"Tolerancia superior\",\"xqq\",\"Sigma\",\"Cp\",\"Cpd\"}\n",
        "faltantes = esperados - set(resumen.index)\n",
        "if faltantes:\n",
        "    print(\"⚠️ Faltan estadísticos en el resumen:\", faltantes)\n",
        "else:\n",
        "    print(\"✔️ Resumen completo y consistente.\")\n"
      ],
      "metadata": {
        "id": "tKRNfEZ4r0P6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "p36",
      "language": "python",
      "name": "p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "name": "SPC Analysis_V1.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}